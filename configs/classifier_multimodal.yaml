action: train # train or test
name: ???
modality: ["EMG"]
shift: D1-D1
split: train
resume_from: ???
num_clips: 10
wandb_name: 'Multimodal_classification'
in_features: 1024
total_batch: 128 # total batch size if training is done with gradient accumulation
batch_size: 32 # batch size for the forward
gpus: null # gpus adopted
logname: null # name of the logs
models_dir: null # directory containing all the models
wandb_dir: Experiment_logs # directory for the wandb logs

augmentation: False

train:
  num_iter: 300        # number of training iterations with total_batch size
  eval_freq: 50        # evaluation frequency
  num_clips: 10        # clips adopted in training
  embedding_size: 1024 # size of the embedding vector
  dense_sampling:      # sampling version adopted in training for each modality
    RGB: True
    EMG: False
  num_frames_per_clip: # number of frames adopted in training for each modality
    RGB: 16
    EMG: 32

save: 
  num_clips: 10        # clips adopted in training
  dense_sampling:      # sampling version adopted in training for each modality
    RGB: True
    EMG: False
  num_frames_per_clip: # number of frames adopted in training for each modality
    RGB: 16
    EMG: 32

test:
  num_clips: 10        # number of clips in testing
  dense_sampling:      # sampling version adopted in test for each modality
    RGB: True
    EMG: False
  num_frames_per_clip: # number of frames adopted in test for each modality
    RGB: 16
    EMG: 32

dataset:
  annotations_path: 'train_val' # path for the annotations data
  shift: D1-D1  # shifts of the dataset
  workers: 4                  # number of workers for the dataloader
  stride: 1                   # stride in case of dense sampling
  EMG:
    features_name: 'Epic features/emg/features_epic'
  RGB:
    data_path: '../ek_data/frames'  
    features_name: 'Epic features/rgb/FT_D_D1_16f_10c' # path for the frames data

models: # models adopted              # Model for each modality
  EMG:
    model: Unimodal_classifier  # model name
    dropout: 0.5                      # dropout adopted   
    normalize: False                  # normalization adopted         
    transform: False                  # transformation adopted        
    lr: 0.1                         # learning rate  
    lr_steps: 200                      # steps before reducing learning rate
    sgd_momentum: 0.9                 # momentum for the optimizer
    weight_decay: 0.001  
  RGB:
    model: Unimodal_classifier  # model name
    dropout: 0.5                      # dropout adopted   
    normalize: False                  # normalization adopted         
    transform: False                  # transformation adopted        
    lr: 0.3                          # learning rate  
    lr_steps: 25                      # steps before reducing learning rate
    sgd_momentum: 0.9                 # momentum for the optimizer
    weight_decay: 0.001     