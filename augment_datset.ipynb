{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!rm -rf sample_data\n",
        "\n",
        "!git clone https://github.com/gabbiurlaro/aml22-ego.git aml22-ego\n",
        "!cd aml22-ego && git checkout vae"
      ],
      "metadata": {
        "id": "2GdURZvMjb9U",
        "outputId": "274ea98a-54d0-47c6-9afc-475bed27d4ba",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'aml22-ego'...\n",
            "remote: Enumerating objects: 3462, done.\u001b[K\n",
            "remote: Counting objects: 100% (114/114), done.\u001b[K\n",
            "remote: Compressing objects: 100% (48/48), done.\u001b[K\n",
            "remote: Total 3462 (delta 74), reused 94 (delta 66), pack-reused 3348\u001b[K\n",
            "Receiving objects: 100% (3462/3462), 1.43 GiB | 24.84 MiB/s, done.\n",
            "Resolving deltas: 100% (2540/2540), done.\n",
            "Updating files: 100% (45/45), done.\n",
            "Updating files: 100% (150/150), done.\n",
            "Branch 'vae' set up to track remote branch 'vae' from 'origin'.\n",
            "Switched to a new branch 'vae'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount google drive \n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "FhUB2tNujdxM",
        "outputId": "b6392b34-f2b5-4b9d-e582-c764efe22117",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install conda\n",
        "\n",
        "!pip install -q condacolab\n",
        "import condacolab\n",
        "condacolab.install()"
      ],
      "metadata": {
        "id": "AuAI_gnfjeQj",
        "outputId": "8f73937e-19f8-41ad-e032-30b1dc8fd20d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m‚ú®üç∞‚ú® Everything looks OK!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!mkdir -p /usr/local/envs/egovision\n",
        "!tar xf /content/drive/MyDrive/egovision.tar.gz --directory=/usr/local/envs/egovision"
      ],
      "metadata": {
        "id": "7qH1xQMvjhv_"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "cd aml22-ego"
      ],
      "metadata": {
        "id": "HcrNzdpzkJ49"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "6pVgmYFLjPgt",
        "outputId": "d8ebf913-65c1-467e-ca11-db5cc3cdf288",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 531
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-7b5765a39b56>\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloaders\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mActionNetDataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m dataset_conf = {\n",
            "\u001b[0;32m/content/aml22-ego/utils/loaders.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrandint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogger\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlogger\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m ''' \n",
            "\u001b[0;32m/content/aml22-ego/utils/logger.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlogging\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mcoloredlogs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'coloredlogs'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "import pickle \n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pywt\n",
        "import torch\n",
        "import os\n",
        "import torch.nn.functional as F\n",
        "from scipy.interpolate import CubicSpline\n",
        "import random\n",
        "from torch.utils.data import Dataset\n",
        "from utils.loaders import ActionNetDataset\n",
        "\n",
        "dataset_conf = {\n",
        "  'annotations_path': '../drive/MyDrive/train_val_EMG',\n",
        "  'shift': 'ActionNet-ActionNet',\n",
        "  'workers': 4,\n",
        "  'stride': 2,\n",
        "  'resolution': 224\n",
        "}\n",
        "train =  ActionNetDataset('ActionNet', ['EMG'],'train',\n",
        "                                   dataset_conf, {'EMG': 32}, 5, {'EMG': False},\n",
        "                                   None, load_feat=False, additional_info=True)\n",
        "\n",
        "test =  ActionNetDataset('ActionNet', ['EMG'],' test',\n",
        "                                   dataset_conf, {'EMG': 32}, 5, {'EMG': False},\n",
        "                                   None, load_feat=False, additional_info=True)\n",
        "                                     \n",
        "train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hw5qXKROjPgv"
      },
      "outputs": [],
      "source": [
        "def wavelet_decomposition(signal, wavelet_name, decomposition_level, detail_factor):\n",
        "    coeffs = pywt.wavedec(signal, wavelet=wavelet_name, level=decomposition_level)\n",
        "    cA, cD = coeffs[0], coeffs[1:]  # Approximation and detail coefficients\n",
        "    \n",
        "    # Modify detail coefficients\n",
        "    cD_modified = [detail_factor * cd for cd in cD]\n",
        "    \n",
        "    # Reconstruct the augmented signal\n",
        "    augmented_coeffs = [cA] + cD_modified\n",
        "    augmented_signal = np.array(pywt.waverec(augmented_coeffs, wavelet=wavelet_name))\n",
        "    \n",
        "    return augmented_signal\n",
        "\n",
        "\n",
        "class WaveletDecompositionTransform:\n",
        "    def __init__(self, wavelet_name, decomposition_level, detail_factor, num_clips):\n",
        "        self.wavelet_name = wavelet_name\n",
        "        self.decomposition_level = decomposition_level\n",
        "        self.detail_factor = detail_factor\n",
        "        self.num_clips = num_clips\n",
        "    \n",
        "    def __call__(self, sample):\n",
        "        signals = sample['features_EMG']\n",
        "        augmented_signals = []\n",
        "        for i in range(self.num_clips):\n",
        "          augmented_signals.append(wavelet_decomposition(torch.Tensor(signals[i]), self.wavelet_name, self.decomposition_level, self.detail_factor))\n",
        "        # Create a new augmented sample\n",
        "        augmented_sample = {\n",
        "            'features_EMG': np.array(augmented_signals),\n",
        "            'label': sample['label'],\n",
        "            'uid': sample['uid'],\n",
        "            'untrimmed_video_name': sample['untrimmed_video_name']\n",
        "        }\n",
        "        \n",
        "        return augmented_sample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LGxv8xQ7jPgv"
      },
      "outputs": [],
      "source": [
        "def magnitude_warping(signal, variance=0.01):\n",
        "    T = signal.size(0)\n",
        "    t = torch.linspace(0, 1, T)  # Equidistant time points\n",
        "    r = torch.randn(T)  # Random numbers from a normal distribution\n",
        "    r = torch.clamp(r, -2.0, 2.0)  # Limit the range of random numbers to avoid extreme warping\n",
        "    \n",
        "    # Generate a smooth curve using cubic splines\n",
        "    spline = CubicSpline(t, r)\n",
        "    cubic_spline = torch.from_numpy(spline(t)).float()\n",
        "    \n",
        "    # Elementwise product of the interpolated curve with the signal\n",
        "    warped_signal = np.array(signal * (1.0 + variance * cubic_spline))\n",
        "\n",
        "    return warped_signal\n",
        "\n",
        "class MagnitudeWarpingTransform:\n",
        "    def __init__(self, variance, num_clips):\n",
        "        self.variance= variance\n",
        "        self.num_clips = num_clips\n",
        "    \n",
        "    def __call__(self, sample):\n",
        "        signals = sample['features_EMG']\n",
        "        augmented_signals = []\n",
        "        for i in range(self.num_clips):\n",
        "          augmented_signals.append(magnitude_warping(torch.Tensor(signals[i]), variance=self.variance))\n",
        "        # Create a new augmented sample\n",
        "        augmented_sample = {\n",
        "            'features_EMG': np.array(augmented_signals),\n",
        "            'label': sample['label'],\n",
        "            'uid': sample['uid'],\n",
        "            'untrimmed_video_name': sample['untrimmed_video_name']\n",
        "        }\n",
        "        \n",
        "        return augmented_sample\n",
        "\n",
        "# Example usage\n",
        "#signal = torch.randn(1024)  # Assuming input signal of size 1024\n",
        "#warped_signal = magnitude_warping(signal, variance=0.01)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YtoamY34jPgw"
      },
      "outputs": [],
      "source": [
        "class sEMGSimulationSS1Transform:\n",
        "    def __init__(self, fl, fh, num_electrodes=1):\n",
        "        self.fl = fl\n",
        "        self.fh = fh\n",
        "        self.num_electrodes = num_electrodes\n",
        "\n",
        "    def __call__(self, x):\n",
        "        batch_size, signal_length = x.size()\n",
        "\n",
        "        # Generate random vector w from standard normal distribution\n",
        "        w = torch.randn(batch_size, self.num_electrodes, signal_length)\n",
        "\n",
        "        # Apply shaping filter g\n",
        "        g = torch.sqrt((self.fh ** 2 * self.fl ** 2) / ((self.fl ** 2 + self.f ** 2) * (self.fh ** 2 + self.f ** 2) ** 2))\n",
        "        w_filtered = torch.fft.irfft(torch.fft.rfft(w, signal_length) * g.unsqueeze(1), signal_length, signal_ndim=1)\n",
        "\n",
        "        # Generate Gaussian noise\n",
        "        noise = torch.randn(batch_size, self.num_electrodes, signal_length)\n",
        "\n",
        "        # Generate lowpass filtered (LPF) signal\n",
        "        lp_filtered_signal = F.avg_pool1d(x.unsqueeze(1), kernel_size=15, stride=1).squeeze(1)\n",
        "\n",
        "        # Generate synthetic sEMG signal\n",
        "        xi_star = (w_filtered * lp_filtered_signal.unsqueeze(1)) + noise\n",
        "\n",
        "        return xi_star\n",
        "\n",
        "\n",
        "class sEMGSimulationSS2Transform:\n",
        "    def __init__(self, alpha, beta, num_electrodes=1):\n",
        "        self.alpha = alpha\n",
        "        self.beta = beta\n",
        "        self.num_electrodes = num_electrodes\n",
        "\n",
        "    def __call__(self, x):\n",
        "        batch_size, signal_length = x.size()\n",
        "\n",
        "        # Generate random vector w from standard normal distribution\n",
        "        w = torch.randn(batch_size, self.num_electrodes, signal_length)\n",
        "\n",
        "        # Apply shaping filter g\n",
        "        g = torch.sqrt((fh ** 2 * fl ** 2) / ((fl ** 2 + f ** 2) * (fh ** 2 + f ** 2) ** 2))\n",
        "        w_filtered = torch.fft.irfft(torch.fft.rfft(w, signal_length) * g.unsqueeze(1), signal_length, signal_ndim=1)\n",
        "\n",
        "        # Generate sEMG variance sigma^2 from inverse gamma distribution\n",
        "        sigma_sq = torch.randn(batch_size, self.num_electrodes, signal_length).abs().pow(-2 * self.alpha)\n",
        "\n",
        "        # Generate Gaussian noise\n",
        "        noise = torch.randn(batch_size, self.num_electrodes, signal_length)\n",
        "\n",
        "        # Generate synthetic sEMG signal\n",
        "        xi_star = (w_filtered * torch.sqrt(sigma_sq)) + noise\n",
        "\n",
        "        return xi_star\n",
        "\n",
        "\n",
        "class sEMGDataset(Dataset):\n",
        "    def __init__(self, data):\n",
        "        self.data = data\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        sample = self.data[index]\n",
        "        return sample\n",
        "\n",
        "\n",
        "# Example usage\n",
        "fl = 10  # Low frequency cutoff\n",
        "fh = 100  # High frequency cutoff\n",
        "alpha = 2  # Alpha parameter for inverse gamma distribution\n",
        "beta = 3  # Beta parameter for inverse gamma distribution\n",
        "\n",
        "# Create synthetic sEMG dataset using SS1 transform\n",
        "ss1_transform = sEMGSimulationSS1Transform(fl, fh)\n",
        "synthetic_dataset_ss1 = sEMGDataset([ss1_transform(real_data) for real_data in real_dataset])\n",
        "\n",
        "# Create synthetic sEMG dataset using SS2 transform\n",
        "ss2_transform = sEMGSimulationSS2Transform(alpha, beta)\n",
        "synthetic_dataset_ss2 = sEMGDataset([ss2_transform(real_data) for real_data in real_dataset])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "73FRNsZBjPgw"
      },
      "outputs": [],
      "source": [
        "class SlidingWindowTransform:\n",
        "    def __init__(self, window_length, overlap=False):\n",
        "        self.window_length = window_length\n",
        "        self.overlap = overlap\n",
        "\n",
        "    def __call__(self, x):\n",
        "        num_segments = len(x) // self.window_length\n",
        "        if self.overlap:\n",
        "            stride = self.window_length // 2\n",
        "        else:\n",
        "            stride = self.window_length\n",
        "\n",
        "        segments = []\n",
        "        for i in range(num_segments):\n",
        "            start = i * stride\n",
        "            end = start + self.window_length\n",
        "            segment = x[start:end]\n",
        "            segments.append(segment)\n",
        "\n",
        "        return torch.stack(segments)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HEAdkjQMjPgw"
      },
      "outputs": [],
      "source": [
        "class AugmentorOneTransform:\n",
        "    def __init__(self, augmentations):\n",
        "        self.augmentations = augmentations\n",
        "\n",
        "    def __call__(self, x):\n",
        "        augmentation = random.choice(self.augmentations)\n",
        "        return augmentation(x)\n",
        "\n",
        "class AugmentorAllTransform:\n",
        "    def __init__(self, augmentations):\n",
        "        self.augmentations = augmentations\n",
        "\n",
        "    def __call__(self, x):\n",
        "        for augmentation in self.augmentations:\n",
        "            x = augmentation(x)\n",
        "        return x\n",
        "\n",
        "class AugmentorRandomTransform:\n",
        "    def __init__(self, augmentations, p):\n",
        "        self.augmentations = augmentations\n",
        "        self.p = p\n",
        "\n",
        "    def __call__(self, x):\n",
        "        for augmentation in self.augmentations:\n",
        "            if random.random() > self.p:\n",
        "                x = augmentation(x)\n",
        "        return x\n",
        "\n",
        "class AugmentedDataset(Dataset):\n",
        "    def __init__(self, dataset, augmentation_transform):\n",
        "        self.dataset = dataset\n",
        "        self.augmentation_transform = augmentation_transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataset)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        x = self.dataset[index]\n",
        "        x_augmented = self.augmentation_transform(x)\n",
        "        return x_augmented\n",
        "\n",
        "# Example usage\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ddtzSq60jPgw"
      },
      "outputs": [],
      "source": [
        "variance = 0.01\n",
        "wavelet_name = 'db4'  # Wavelet name (e.g., Daubechies 4)\n",
        "decomposition_level = 3  # Number of decomposition levels\n",
        "detail_factor = 0.5  # Scaling factor for modifying detail coefficients\n",
        "num_clips = 5\n",
        "\n",
        "\n",
        "wavelet_transform = WaveletDecompositionTransform(wavelet_name, decomposition_level, detail_factor, num_clips)\n",
        "magnitude_warp_transform = MagnitudeWarpingTransform(variance, num_clips),\n",
        "ss1_transform = sEMGSimulationSS1Transform(fl=10, fh=100)\n",
        "ss2_transform = sEMGSimulationSS2Transform(alpha=1.0, beta=2.0)\n",
        "sw_transform = SlidingWindowTransform(window_length=100, overlap=True)\n",
        "\n",
        "augmentations = [wavelet_transform, magnitude_warp_transform, ss1_transform, ss2_transform]\n",
        "augmentor_one_transform = AugmentorOneTransform(augmentations=augmentations)\n",
        "augmentor_all_transform = AugmentorAllTransform(augmentations=augmentations)\n",
        "augmentor_random_transform = AugmentorRandomTransform(augmentations=augmentations, p=0.5)\n",
        "\n",
        "augmented_dataset_ao = AugmentedDataset(train, augmentation_transform=augmentor_one_transform)\n",
        "augmented_dataset_aa = AugmentedDataset(train, augmentation_transform=augmentor_all_transform)\n",
        "augmented_dataset_ar = AugmentedDataset(train, augmentation_transform=augmentor_random_transform)\n",
        "augmented_dataset_sw = AugmentedDataset(train, augmentation_transform=sw_transform)\n",
        "\n",
        "\n",
        "augmented_dataset_aa\n",
        "# augmented_samples_train = [transform(train['features'][i]) for i in range(len(train['features']))]\n",
        "# out_train = {'features': list(augmented_samples_train)}\n",
        "\n",
        "# augmented_samples_test = [transform(test['features'][i]) for i in range(len(test['features']))]\n",
        "# out_test = {'features': list(augmented_samples_test)}\n",
        "\n",
        "# filename = './ActionNet_augmented_clips'\n",
        "# with open(f\"{filename}_train.pkl\", \"wb\") as file:\n",
        "#             pickle.dump(out_train, file)\n",
        "\n",
        "# with open(f\"{filename}_test.pkl\", \"wb\") as file:\n",
        "#             pickle.dump(out_test, file)"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}