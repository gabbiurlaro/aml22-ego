{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pywt\n",
    "import torch\n",
    "import os\n",
    "import torch.nn.functional as F\n",
    "from scipy.interpolate import CubicSpline\n",
    "import random\n",
    "from torch.utils.data import Dataset\n",
    "from utils.loaders import ActionNetDataset\n",
    "\n",
    "dataset_conf = {\n",
    "  'annotations_path': '../drive/MyDrive/train_val_EMG',\n",
    "  'shift': 'ActionNet-ActionNet',\n",
    "  'workers': 4,\n",
    "  'stride': 2,\n",
    "  'resolution': 224\n",
    "}\n",
    "train =  ActionNetDataset('ActionNet', ['EMG'],'train',\n",
    "                                   dataset_conf, {'EMG': 32}, 5, {'EMG': False},\n",
    "                                   None, load_feat=False, additional_info=True)\n",
    "\n",
    "test =  ActionNetDataset('ActionNet', ['EMG'],' test',\n",
    "                                   dataset_conf, {'EMG': 32}, 5, {'EMG': False},\n",
    "                                   None, load_feat=False, additional_info=True)\n",
    "                                     \n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wavelet_decomposition(signal, wavelet_name, decomposition_level, detail_factor):\n",
    "    coeffs = pywt.wavedec(signal, wavelet=wavelet_name, level=decomposition_level)\n",
    "    cA, cD = coeffs[0], coeffs[1:]  # Approximation and detail coefficients\n",
    "    \n",
    "    # Modify detail coefficients\n",
    "    cD_modified = [detail_factor * cd for cd in cD]\n",
    "    \n",
    "    # Reconstruct the augmented signal\n",
    "    augmented_coeffs = [cA] + cD_modified\n",
    "    augmented_signal = np.array(pywt.waverec(augmented_coeffs, wavelet=wavelet_name))\n",
    "    \n",
    "    return augmented_signal\n",
    "\n",
    "\n",
    "class WaveletDecompositionTransform:\n",
    "    def __init__(self, wavelet_name, decomposition_level, detail_factor, num_clips):\n",
    "        self.wavelet_name = wavelet_name\n",
    "        self.decomposition_level = decomposition_level\n",
    "        self.detail_factor = detail_factor\n",
    "        self.num_clips = num_clips\n",
    "    \n",
    "    def __call__(self, sample):\n",
    "        signals = sample['features_EMG']\n",
    "        augmented_signals = []\n",
    "        for i in range(self.num_clips):\n",
    "          augmented_signals.append(wavelet_decomposition(torch.Tensor(signals[i]), self.wavelet_name, self.decomposition_level, self.detail_factor))\n",
    "        # Create a new augmented sample\n",
    "        augmented_sample = {\n",
    "            'features_EMG': np.array(augmented_signals),\n",
    "            'label': sample['label'],\n",
    "            'uid': sample['uid'],\n",
    "            'untrimmed_video_name': sample['untrimmed_video_name']\n",
    "        }\n",
    "        \n",
    "        return augmented_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def magnitude_warping(signal, variance=0.01):\n",
    "    T = signal.size(0)\n",
    "    t = torch.linspace(0, 1, T)  # Equidistant time points\n",
    "    r = torch.randn(T)  # Random numbers from a normal distribution\n",
    "    r = torch.clamp(r, -2.0, 2.0)  # Limit the range of random numbers to avoid extreme warping\n",
    "    \n",
    "    # Generate a smooth curve using cubic splines\n",
    "    spline = CubicSpline(t, r)\n",
    "    cubic_spline = torch.from_numpy(spline(t)).float()\n",
    "    \n",
    "    # Elementwise product of the interpolated curve with the signal\n",
    "    warped_signal = np.array(signal * (1.0 + variance * cubic_spline))\n",
    "\n",
    "    return warped_signal\n",
    "\n",
    "class MagnitudeWarpingTransform:\n",
    "    def __init__(self, variance, num_clips):\n",
    "        self.variance= variance\n",
    "        self.num_clips = num_clips\n",
    "    \n",
    "    def __call__(self, sample):\n",
    "        signals = sample['features_EMG']\n",
    "        augmented_signals = []\n",
    "        for i in range(self.num_clips):\n",
    "          augmented_signals.append(magnitude_warping(torch.Tensor(signals[i]), variance=self.variance))\n",
    "        # Create a new augmented sample\n",
    "        augmented_sample = {\n",
    "            'features_EMG': np.array(augmented_signals),\n",
    "            'label': sample['label'],\n",
    "            'uid': sample['uid'],\n",
    "            'untrimmed_video_name': sample['untrimmed_video_name']\n",
    "        }\n",
    "        \n",
    "        return augmented_sample\n",
    "\n",
    "# Example usage\n",
    "#signal = torch.randn(1024)  # Assuming input signal of size 1024\n",
    "#warped_signal = magnitude_warping(signal, variance=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class sEMGSimulationSS1Transform:\n",
    "    def __init__(self, fl, fh, num_electrodes=1):\n",
    "        self.fl = fl\n",
    "        self.fh = fh\n",
    "        self.num_electrodes = num_electrodes\n",
    "\n",
    "    def __call__(self, x):\n",
    "        batch_size, signal_length = x.size()\n",
    "\n",
    "        # Generate random vector w from standard normal distribution\n",
    "        w = torch.randn(batch_size, self.num_electrodes, signal_length)\n",
    "\n",
    "        # Apply shaping filter g\n",
    "        g = torch.sqrt((self.fh ** 2 * self.fl ** 2) / ((self.fl ** 2 + self.f ** 2) * (self.fh ** 2 + self.f ** 2) ** 2))\n",
    "        w_filtered = torch.fft.irfft(torch.fft.rfft(w, signal_length) * g.unsqueeze(1), signal_length, signal_ndim=1)\n",
    "\n",
    "        # Generate Gaussian noise\n",
    "        noise = torch.randn(batch_size, self.num_electrodes, signal_length)\n",
    "\n",
    "        # Generate lowpass filtered (LPF) signal\n",
    "        lp_filtered_signal = F.avg_pool1d(x.unsqueeze(1), kernel_size=15, stride=1).squeeze(1)\n",
    "\n",
    "        # Generate synthetic sEMG signal\n",
    "        xi_star = (w_filtered * lp_filtered_signal.unsqueeze(1)) + noise\n",
    "\n",
    "        return xi_star\n",
    "\n",
    "\n",
    "class sEMGSimulationSS2Transform:\n",
    "    def __init__(self, alpha, beta, num_electrodes=1):\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        self.num_electrodes = num_electrodes\n",
    "\n",
    "    def __call__(self, x):\n",
    "        batch_size, signal_length = x.size()\n",
    "\n",
    "        # Generate random vector w from standard normal distribution\n",
    "        w = torch.randn(batch_size, self.num_electrodes, signal_length)\n",
    "\n",
    "        # Apply shaping filter g\n",
    "        g = torch.sqrt((fh ** 2 * fl ** 2) / ((fl ** 2 + f ** 2) * (fh ** 2 + f ** 2) ** 2))\n",
    "        w_filtered = torch.fft.irfft(torch.fft.rfft(w, signal_length) * g.unsqueeze(1), signal_length, signal_ndim=1)\n",
    "\n",
    "        # Generate sEMG variance sigma^2 from inverse gamma distribution\n",
    "        sigma_sq = torch.randn(batch_size, self.num_electrodes, signal_length).abs().pow(-2 * self.alpha)\n",
    "\n",
    "        # Generate Gaussian noise\n",
    "        noise = torch.randn(batch_size, self.num_electrodes, signal_length)\n",
    "\n",
    "        # Generate synthetic sEMG signal\n",
    "        xi_star = (w_filtered * torch.sqrt(sigma_sq)) + noise\n",
    "\n",
    "        return xi_star\n",
    "\n",
    "\n",
    "class sEMGDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        sample = self.data[index]\n",
    "        return sample\n",
    "\n",
    "\n",
    "# Example usage\n",
    "fl = 10  # Low frequency cutoff\n",
    "fh = 100  # High frequency cutoff\n",
    "alpha = 2  # Alpha parameter for inverse gamma distribution\n",
    "beta = 3  # Beta parameter for inverse gamma distribution\n",
    "\n",
    "# Create synthetic sEMG dataset using SS1 transform\n",
    "ss1_transform = sEMGSimulationSS1Transform(fl, fh)\n",
    "synthetic_dataset_ss1 = sEMGDataset([ss1_transform(real_data) for real_data in real_dataset])\n",
    "\n",
    "# Create synthetic sEMG dataset using SS2 transform\n",
    "ss2_transform = sEMGSimulationSS2Transform(alpha, beta)\n",
    "synthetic_dataset_ss2 = sEMGDataset([ss2_transform(real_data) for real_data in real_dataset])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SlidingWindowTransform:\n",
    "    def __init__(self, window_length, overlap=False):\n",
    "        self.window_length = window_length\n",
    "        self.overlap = overlap\n",
    "\n",
    "    def __call__(self, x):\n",
    "        num_segments = len(x) // self.window_length\n",
    "        if self.overlap:\n",
    "            stride = self.window_length // 2\n",
    "        else:\n",
    "            stride = self.window_length\n",
    "\n",
    "        segments = []\n",
    "        for i in range(num_segments):\n",
    "            start = i * stride\n",
    "            end = start + self.window_length\n",
    "            segment = x[start:end]\n",
    "            segments.append(segment)\n",
    "\n",
    "        return torch.stack(segments)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AugmentorOneTransform:\n",
    "    def __init__(self, augmentations):\n",
    "        self.augmentations = augmentations\n",
    "\n",
    "    def __call__(self, x):\n",
    "        augmentation = random.choice(self.augmentations)\n",
    "        return augmentation(x)\n",
    "\n",
    "class AugmentorAllTransform:\n",
    "    def __init__(self, augmentations):\n",
    "        self.augmentations = augmentations\n",
    "\n",
    "    def __call__(self, x):\n",
    "        for augmentation in self.augmentations:\n",
    "            x = augmentation(x)\n",
    "        return x\n",
    "\n",
    "class AugmentorRandomTransform:\n",
    "    def __init__(self, augmentations, p):\n",
    "        self.augmentations = augmentations\n",
    "        self.p = p\n",
    "\n",
    "    def __call__(self, x):\n",
    "        for augmentation in self.augmentations:\n",
    "            if random.random() > self.p:\n",
    "                x = augmentation(x)\n",
    "        return x\n",
    "\n",
    "class AugmentedDataset(Dataset):\n",
    "    def __init__(self, dataset, augmentation_transform):\n",
    "        self.dataset = dataset\n",
    "        self.augmentation_transform = augmentation_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        x = self.dataset[index]\n",
    "        x_augmented = self.augmentation_transform(x)\n",
    "        return x_augmented\n",
    "\n",
    "# Example usage\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variance = 0.01\n",
    "wavelet_name = 'db4'  # Wavelet name (e.g., Daubechies 4)\n",
    "decomposition_level = 3  # Number of decomposition levels\n",
    "detail_factor = 0.5  # Scaling factor for modifying detail coefficients\n",
    "num_clips = 5\n",
    "\n",
    "\n",
    "wavelet_transform = WaveletDecompositionTransform(wavelet_name, decomposition_level, detail_factor, num_clips)\n",
    "magnitude_warp_transform = MagnitudeWarpingTransform(variance, num_clips),\n",
    "ss1_transform = sEMGSimulationSS1Transform(fl=10, fh=100)\n",
    "ss2_transform = sEMGSimulationSS2Transform(alpha=1.0, beta=2.0)\n",
    "sw_transform = SlidingWindowTransform(window_length=100, overlap=True)\n",
    "\n",
    "augmentations = [wavelet_transform, magnitude_warp_transform, ss1_transform, ss2_transform]\n",
    "augmentor_one_transform = AugmentorOneTransform(augmentations=augmentations)\n",
    "augmentor_all_transform = AugmentorAllTransform(augmentations=augmentations)\n",
    "augmentor_random_transform = AugmentorRandomTransform(augmentations=augmentations, p=0.5)\n",
    "\n",
    "augmented_dataset_ao = AugmentedDataset(train, augmentation_transform=augmentor_one_transform)\n",
    "augmented_dataset_aa = AugmentedDataset(train, augmentation_transform=augmentor_all_transform)\n",
    "augmented_dataset_ar = AugmentedDataset(train, augmentation_transform=augmentor_random_transform)\n",
    "augmented_dataset_sw = AugmentedDataset(train, augmentation_transform=sw_transform)\n",
    "\n",
    "\n",
    "augmented_dataset_aa\n",
    "# augmented_samples_train = [transform(train['features'][i]) for i in range(len(train['features']))]\n",
    "# out_train = {'features': list(augmented_samples_train)}\n",
    "\n",
    "# augmented_samples_test = [transform(test['features'][i]) for i in range(len(test['features']))]\n",
    "# out_test = {'features': list(augmented_samples_test)}\n",
    "\n",
    "# filename = './ActionNet_augmented_clips'\n",
    "# with open(f\"{filename}_train.pkl\", \"wb\") as file:\n",
    "#             pickle.dump(out_train, file)\n",
    "\n",
    "# with open(f\"{filename}_test.pkl\", \"wb\") as file:\n",
    "#             pickle.dump(out_test, file)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
