{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!rm -rf sample_data\n",
        "\n",
        "!git clone https://github.com/gabbiurlaro/aml22-ego.git aml22-ego\n",
        "!cd aml22-ego && git checkout vae"
      ],
      "metadata": {
        "id": "2GdURZvMjb9U",
        "outputId": "e6a7824b-d196-4c86-f490-1dd86ac15d5b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'aml22-ego'...\n",
            "remote: Enumerating objects: 3465, done.\u001b[K\n",
            "remote: Counting objects: 100% (110/110), done.\u001b[K\n",
            "remote: Compressing objects: 100% (51/51), done.\u001b[K\n",
            "^C\n",
            "/bin/bash: line 0: cd: aml22-ego: No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount google drive \n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "FhUB2tNujdxM",
        "outputId": "c9699e49-a5ee-42c9-f385-622d5190b15c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install conda\n",
        "\n",
        "!pip install -q condacolab\n",
        "import condacolab\n",
        "condacolab.install()"
      ],
      "metadata": {
        "id": "AuAI_gnfjeQj",
        "outputId": "52a21b19-81b8-45f7-a16d-1f6beff580fb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mâœ¨ðŸ°âœ¨ Everything looks OK!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Testo del titolo predefinito\n",
        "# Create a conda environment\n",
        "#!conda env create --name egovision -f aml22-ego/requirements.yaml\n",
        "\n",
        "!mkdir -p /usr/local/envs/egovision\n",
        "!tar xf /content/drive/MyDrive/egovision.tar.gz --directory=/usr/local/envs/egovision"
      ],
      "metadata": {
        "id": "7qH1xQMvjhv_"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "cd aml22-ego & git pull origin vae"
      ],
      "metadata": {
        "id": "jItTAWYnuUO5",
        "outputId": "46593439-8370-4921-e915-e77f864bae30",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Updating 64aa934..889b0dc\n",
            "Fast-forward\n",
            " utils/loaders.py | 2 +-\n",
            " 1 file changed, 1 insertion(+), 1 deletion(-)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "bash: line 1: cd: aml22-ego: No such file or directory\n",
            "From https://github.com/gabbiurlaro/aml22-ego\n",
            " * branch            vae        -> FETCH_HEAD\n",
            "   64aa934..889b0dc  vae        -> origin/vae\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "6pVgmYFLjPgt",
        "outputId": "a69257cc-41fe-4a56-a48c-1e69a1431b9f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              features\n",
              "0    {'features_EMG': [[0.034334745, 0.030711306, 0...\n",
              "1    {'features_EMG': [[0.1405246, 1.2171749, 0.150...\n",
              "2    {'features_EMG': [[0.35329345, 0.17335, 0.3205...\n",
              "3    {'features_EMG': [[0.24483056, 0.13764213, 0.1...\n",
              "4    {'features_EMG': [[0.87739646, 0.15978348, 0.1...\n",
              "..                                                 ...\n",
              "521  {'features_EMG': [[0.060848605, 0.17875163, 0....\n",
              "522  {'features_EMG': [[0.111652814, 0.030604776, 0...\n",
              "523  {'features_EMG': [[0.15666321, 0.025441293, 0....\n",
              "524  {'features_EMG': [[1.1815412, 0.025431821, 0.1...\n",
              "525  {'features_EMG': [[0.25301883, 0.034086157, 0....\n",
              "\n",
              "[526 rows x 1 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b3da9bc3-dded-48c2-b815-1cda24d6be43\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>features</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>{'features_EMG': [[0.034334745, 0.030711306, 0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>{'features_EMG': [[0.1405246, 1.2171749, 0.150...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>{'features_EMG': [[0.35329345, 0.17335, 0.3205...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>{'features_EMG': [[0.24483056, 0.13764213, 0.1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>{'features_EMG': [[0.87739646, 0.15978348, 0.1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>521</th>\n",
              "      <td>{'features_EMG': [[0.060848605, 0.17875163, 0....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>522</th>\n",
              "      <td>{'features_EMG': [[0.111652814, 0.030604776, 0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>523</th>\n",
              "      <td>{'features_EMG': [[0.15666321, 0.025441293, 0....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>524</th>\n",
              "      <td>{'features_EMG': [[1.1815412, 0.025431821, 0.1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>525</th>\n",
              "      <td>{'features_EMG': [[0.25301883, 0.034086157, 0....</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>526 rows Ã— 1 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b3da9bc3-dded-48c2-b815-1cda24d6be43')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b3da9bc3-dded-48c2-b815-1cda24d6be43 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b3da9bc3-dded-48c2-b815-1cda24d6be43');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ],
      "source": [
        "import pickle \n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pywt\n",
        "import torch\n",
        "import os\n",
        "import torch.nn.functional as F\n",
        "from scipy.interpolate import CubicSpline\n",
        "import random\n",
        "from torch.utils.data import Dataset\n",
        "from utils.loaders import ActionNetDataset\n",
        "\n",
        "dataset_conf = {\n",
        "  \"annotations_path\": '../drive/MyDrive/train_val_EMG',\n",
        "  \"shift\": 'ActionNet-ActionNet',\n",
        "  \"workers\": 4,\n",
        "  \"stride\": 2,\n",
        "  \"resolution\": 224\n",
        "}\n",
        "\n",
        "train =  pd.DataFrame(pd.read_pickle('/content/aml22-ego/saved_features/ACTIONNET_EMG/EMG_no-clip_ActionNet_train.pkl'))\n",
        "test =  pd.DataFrame(pd.read_pickle('/content/aml22-ego/saved_features/ACTIONNET_EMG/EMG_no-clip_ActionNet_test.pkl'))\n",
        "\n",
        "train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "hw5qXKROjPgv"
      },
      "outputs": [],
      "source": [
        "def wavelet_decomposition(signal, wavelet_name, decomposition_level, detail_factor):\n",
        "    coeffs = pywt.wavedec(signal, wavelet=wavelet_name, level=decomposition_level)\n",
        "    cA, cD = coeffs[0], coeffs[1:]  # Approximation and detail coefficients\n",
        "    \n",
        "    # Modify detail coefficients\n",
        "    cD_modified = [detail_factor * cd for cd in cD]\n",
        "    \n",
        "    # Reconstruct the augmented signal\n",
        "    augmented_coeffs = [cA] + cD_modified\n",
        "    augmented_signal = np.array(pywt.waverec(augmented_coeffs, wavelet=wavelet_name))\n",
        "    \n",
        "    return augmented_signal\n",
        "\n",
        "\n",
        "class WaveletDecompositionTransform:\n",
        "    def __init__(self, wavelet_name, decomposition_level, detail_factor, num_clips):\n",
        "        self.wavelet_name = wavelet_name\n",
        "        self.decomposition_level = decomposition_level\n",
        "        self.detail_factor = detail_factor\n",
        "        self.num_clips = num_clips\n",
        "    \n",
        "    def __call__(self, sample):\n",
        "        signals = sample['features_EMG']\n",
        "        augmented_signals = []\n",
        "        for i in range(self.num_clips):\n",
        "          augmented_signals.append(wavelet_decomposition(torch.Tensor(signals[i]), self.wavelet_name, self.decomposition_level, self.detail_factor))\n",
        "        # Create a new augmented sample\n",
        "        augmented_sample = {\n",
        "            'features_EMG': np.array(augmented_signals),\n",
        "            'label': sample['label'],\n",
        "            'uid': sample['uid'],\n",
        "            'untrimmed_video_name': sample['untrimmed_video_name']\n",
        "        }\n",
        "        \n",
        "        return augmented_sample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "LGxv8xQ7jPgv"
      },
      "outputs": [],
      "source": [
        "def magnitude_warping(signal, variance=0.01):\n",
        "    T = signal.size(0)\n",
        "    t = torch.linspace(0, 1, T)  # Equidistant time points\n",
        "    r = torch.randn(T)  # Random numbers from a normal distribution\n",
        "    r = torch.clamp(r, -2.0, 2.0)  # Limit the range of random numbers to avoid extreme warping\n",
        "    \n",
        "    # Generate a smooth curve using cubic splines\n",
        "    spline = CubicSpline(t, r)\n",
        "    cubic_spline = torch.from_numpy(spline(t)).float()\n",
        "    \n",
        "    # Elementwise product of the interpolated curve with the signal\n",
        "    warped_signal = np.array(signal * (1.0 + variance * cubic_spline))\n",
        "\n",
        "    return warped_signal\n",
        "\n",
        "class MagnitudeWarpingTransform:\n",
        "    def __init__(self, variance, num_clips):\n",
        "        self.variance= variance\n",
        "        self.num_clips = num_clips\n",
        "    \n",
        "    def __call__(self, sample):\n",
        "        signals = sample['features_EMG']\n",
        "        augmented_signals = []\n",
        "        for i in range(self.num_clips):\n",
        "          augmented_signals.append(magnitude_warping(torch.Tensor(signals[i]), variance=self.variance))\n",
        "        # Create a new augmented sample\n",
        "        augmented_sample = {\n",
        "            'features_EMG': np.array(augmented_signals),\n",
        "            'label': sample['label'],\n",
        "            'uid': sample['uid'],\n",
        "            'untrimmed_video_name': sample['untrimmed_video_name']\n",
        "        }\n",
        "        \n",
        "        return augmented_sample\n",
        "\n",
        "# Example usage\n",
        "#signal = torch.randn(1024)  # Assuming input signal of size 1024\n",
        "#warped_signal = magnitude_warping(signal, variance=0.01)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "YtoamY34jPgw"
      },
      "outputs": [],
      "source": [
        "class sEMGSimulationSS1Transform:\n",
        "    def __init__(self, fl, fh, num_electrodes=1):\n",
        "        self.fl = fl\n",
        "        self.fh = fh\n",
        "        self.num_electrodes = num_electrodes\n",
        "\n",
        "    def __call__(self, x):\n",
        "        batch_size, signal_length = x.size()\n",
        "\n",
        "        # Generate random vector w from standard normal distribution\n",
        "        w = torch.randn(batch_size, self.num_electrodes, signal_length)\n",
        "\n",
        "        # Apply shaping filter g\n",
        "        g = torch.sqrt((self.fh ** 2 * self.fl ** 2) / ((self.fl ** 2 + self.f ** 2) * (self.fh ** 2 + self.f ** 2) ** 2))\n",
        "        w_filtered = torch.fft.irfft(torch.fft.rfft(w, signal_length) * g.unsqueeze(1), signal_length, signal_ndim=1)\n",
        "\n",
        "        # Generate Gaussian noise\n",
        "        noise = torch.randn(batch_size, self.num_electrodes, signal_length)\n",
        "\n",
        "        # Generate lowpass filtered (LPF) signal\n",
        "        lp_filtered_signal = F.avg_pool1d(x.unsqueeze(1), kernel_size=15, stride=1).squeeze(1)\n",
        "\n",
        "        # Generate synthetic sEMG signal\n",
        "        xi_star = (w_filtered * lp_filtered_signal.unsqueeze(1)) + noise\n",
        "\n",
        "        return xi_star\n",
        "\n",
        "\n",
        "class sEMGSimulationSS2Transform:\n",
        "    def __init__(self, alpha, beta, num_electrodes=1):\n",
        "        self.alpha = alpha\n",
        "        self.beta = beta\n",
        "        self.num_electrodes = num_electrodes\n",
        "\n",
        "    def __call__(self, x):\n",
        "        batch_size, signal_length = x.size()\n",
        "\n",
        "        # Generate random vector w from standard normal distribution\n",
        "        w = torch.randn(batch_size, self.num_electrodes, signal_length)\n",
        "\n",
        "        # Apply shaping filter g\n",
        "        g = torch.sqrt((fh ** 2 * fl ** 2) / ((fl ** 2 + f ** 2) * (fh ** 2 + f ** 2) ** 2))\n",
        "        w_filtered = torch.fft.irfft(torch.fft.rfft(w, signal_length) * g.unsqueeze(1), signal_length, signal_ndim=1)\n",
        "\n",
        "        # Generate sEMG variance sigma^2 from inverse gamma distribution\n",
        "        sigma_sq = torch.randn(batch_size, self.num_electrodes, signal_length).abs().pow(-2 * self.alpha)\n",
        "\n",
        "        # Generate Gaussian noise\n",
        "        noise = torch.randn(batch_size, self.num_electrodes, signal_length)\n",
        "\n",
        "        # Generate synthetic sEMG signal\n",
        "        xi_star = (w_filtered * torch.sqrt(sigma_sq)) + noise\n",
        "\n",
        "        return xi_star\n",
        "\n",
        "\n",
        "class sEMGDataset(Dataset):\n",
        "    def __init__(self, data):\n",
        "        self.data = data\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        sample = self.data[index]\n",
        "        return sample\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "73FRNsZBjPgw"
      },
      "outputs": [],
      "source": [
        "class SlidingWindowTransform:\n",
        "    def __init__(self, window_length, overlap=False):\n",
        "        self.window_length = window_length\n",
        "        self.overlap = overlap\n",
        "\n",
        "    def __call__(self, x):\n",
        "        num_segments = len(x) // self.window_length\n",
        "        if self.overlap:\n",
        "            stride = self.window_length // 2\n",
        "        else:\n",
        "            stride = self.window_length\n",
        "\n",
        "        segments = []\n",
        "        for i in range(num_segments):\n",
        "            start = i * stride\n",
        "            end = start + self.window_length\n",
        "            segment = x[start:end]\n",
        "            segments.append(segment)\n",
        "\n",
        "        return torch.stack(segments)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "HEAdkjQMjPgw"
      },
      "outputs": [],
      "source": [
        "class AugmentorOneTransform:\n",
        "    def __init__(self, augmentations):\n",
        "        self.augmentations = augmentations\n",
        "\n",
        "    def __call__(self, x):\n",
        "        augmentation = random.choice(self.augmentations)\n",
        "        return augmentation(x)\n",
        "\n",
        "class AugmentorAllTransform:\n",
        "    def __init__(self, augmentations):\n",
        "        self.augmentations = augmentations\n",
        "\n",
        "    def __call__(self, x):\n",
        "        for augmentation in self.augmentations:\n",
        "            x = augmentation(x)\n",
        "        return x\n",
        "\n",
        "class AugmentorRandomTransform:\n",
        "    def __init__(self, augmentations, p):\n",
        "        self.augmentations = augmentations\n",
        "        self.p = p\n",
        "\n",
        "    def __call__(self, x):\n",
        "        for augmentation in self.augmentations:\n",
        "            if random.random() > self.p:\n",
        "                x = augmentation(x)\n",
        "        return x\n",
        "\n",
        "class AugmentedDataset():\n",
        "    def __init__(self, dataset, augmentation_transform):\n",
        "        self.dataset = dataset\n",
        "        self.augmentation_transform = augmentation_transform\n",
        "        \n",
        "    \n",
        "    def get_out(self):\n",
        "      augmented_samples_train = [self.augmentation_transform(self.dataset['features'][i]) for i in range(len(self.dataset['features']))]\n",
        "      self.out = {'features': list(augmented_samples_train)}\n",
        "      return self.out\n",
        "\n",
        "\n",
        "\n",
        "# Example usage\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "ddtzSq60jPgw",
        "outputId": "ddc7fee6-163a-4fbc-b850-d3c576267e7f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-76-0049bb304732>\u001b[0m in \u001b[0;36m<cell line: 24>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;31m#0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0maugmented_dataset_aa\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAugmentedDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maugmentation_transform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maugmentor_all_transform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_out\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0maugmented_dataset_0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAugmentedDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maugmented_dataset_aa\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maugmentation_transform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msw_transform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_out\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-74-1d241241ee7f>\u001b[0m in \u001b[0;36mget_out\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_out\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m       \u001b[0maugmented_samples_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maugmentation_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'features'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'features'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'features'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maugmented_samples_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-74-1d241241ee7f>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_out\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m       \u001b[0maugmented_samples_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maugmentation_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'features'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'features'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'features'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maugmented_samples_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-74-1d241241ee7f>\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0maugmentation\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maugmentations\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maugmentation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'tuple' object is not callable"
          ]
        }
      ],
      "source": [
        "sigma = 0.1\n",
        "wavelet_name = 'db7' #Wavelet name (e.g., Daubechies 4)\n",
        "decomposition_level = 5 # # Number of decomposition levels\n",
        "detail_factor = 0 # Scaling factor for modifying detail coefficients\n",
        "  \n",
        "num_clips = 5\n",
        "\n",
        "\n",
        "wavelet_transform = WaveletDecompositionTransform(wavelet_name, decomposition_level, detail_factor, num_clips)\n",
        "magnitude_warp_transform = MagnitudeWarpingTransform(sigma, num_clips),\n",
        "ss1_transform = sEMGSimulationSS1Transform(fl=10, fh=100)\n",
        "ss2_transform = sEMGSimulationSS2Transform(alpha=1.0, beta=2.0)\n",
        "sw_transform = SlidingWindowTransform(window_length=100, overlap=True)\n",
        "\n",
        "augmentations = [wavelet_transform, magnitude_warp_transform, ss1_transform, ss2_transform]\n",
        "augmentor_one_transform = AugmentorOneTransform(augmentations=augmentations)\n",
        "augmentor_all_transform = AugmentorAllTransform(augmentations=augmentations)\n",
        "augmentor_random_transform = AugmentorRandomTransform(augmentations=augmentations, p=0.5)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#0\n",
        "augmented_dataset_aa = AugmentedDataset(train, augmentation_transform=augmentor_all_transform).get_out()\n",
        "augmented_dataset_0 = AugmentedDataset(augmented_dataset_aa, augmentation_transform=sw_transform).get_out()\n",
        "\n",
        "#1\n",
        "augmented_dataset_ao = AugmentedDataset(train, augmentation_transform=augmentor_one_transform).get_out()\n",
        "augmented_dataset_1 = AugmentedDataset(augmented_dataset_ao, augmentation_transform=sw_transform).get_out()\n",
        "\n",
        "#2\n",
        "augmented_dataset_ar = AugmentedDataset(train, augmentation_transform=augmentor_random_transform).get_out()\n",
        "augmented_dataset_2 = AugmentedDataset(augmented_dataset_ar, augmentation_transform=sw_transform).get_out()\n",
        "\n",
        "augmented_dataset_train = {\n",
        "    0:augmented_dataset_0,\n",
        "    1:augmented_dataset_1,\n",
        "    2:augmented_dataset_2\n",
        "}\n",
        "\n",
        "augmented_dataset_aa = AugmentedDataset(test, augmentation_transform=augmentor_all_transform).get_out()\n",
        "augmented_dataset_0 = AugmentedDataset(augmented_dataset_aa, augmentation_transform=sw_transform).get_out()\n",
        "\n",
        "#1\n",
        "augmented_dataset_ao = AugmentedDataset(test, augmentation_transform=augmentor_one_transform).get_out()\n",
        "augmented_dataset_1 = AugmentedDataset(augmented_dataset_ao, augmentation_transform=sw_transform).get_out()\n",
        "\n",
        "#2\n",
        "augmented_dataset_ar = AugmentedDataset(test, augmentation_transform=augmentor_random_transform).get_out()\n",
        "augmented_dataset_2 = AugmentedDataset(augmented_dataset_ar, augmentation_transform=sw_transform).get_out()\n",
        "\n",
        "augmented_dataset_test = {\n",
        "    0:augmented_dataset_0,\n",
        "    1:augmented_dataset_1.get_out(),\n",
        "    2:augmented_dataset_2.get_out()\n",
        "}\n",
        "print(augmented_dataset_test[0].dataset)\n",
        "# augmented_samples_test = [transform(test['features'][i]) for i in range(len(test['features']))]\n",
        "# out_test = {'features': list(augmented_samples_test)}\n",
        "for i in range(3):\n",
        "  filename = './ActionNet_augmented_clips_' + str(i)\n",
        "  with open(f\"{filename}_train.pkl\", \"wb\") as file:\n",
        "            pickle.dump(augmented_dataset_train[i], file)\n",
        "  with open(f\"{filename}_test.pkl\", \"wb\") as file:\n",
        "             pickle.dump(augmented_dataset_test[i], file)\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}