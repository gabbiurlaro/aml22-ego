{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNWeh/LcnKngaQPLlpnIKMr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gabbiurlaro/aml22-ego/blob/vae/Second_colab_runner.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VBPldhy3CmMm",
        "outputId": "c26af4e6-a540-4fb7-9953-20ad2b63451a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'aml22-ego'...\n",
            "remote: Enumerating objects: 4009, done.\u001b[K\n",
            "remote: Counting objects: 100% (661/661), done.\u001b[K\n",
            "remote: Compressing objects: 100% (233/233), done.\u001b[K\n",
            "remote: Total 4009 (delta 447), reused 638 (delta 427), pack-reused 3348\u001b[K\n",
            "Receiving objects: 100% (4009/4009), 1.52 GiB | 26.95 MiB/s, done.\n",
            "Resolving deltas: 100% (2913/2913), done.\n",
            "Updating files: 100% (45/45), done.\n",
            "Updating files: 100% (176/176), done.\n",
            "Branch 'vae' set up to track remote branch 'vae' from 'origin'.\n",
            "Switched to a new branch 'vae'\n"
          ]
        }
      ],
      "source": [
        "!rm -rf sample_data\n",
        "\n",
        "!git clone https://github.com/gabbiurlaro/aml22-ego.git aml22-ego\n",
        "!cd aml22-ego && git checkout vae"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount google drive \n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "dYCTa_3-CqUs",
        "outputId": "be7909e5-8c85-4b86-845d-56e8f720c267",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install conda\n",
        "\n",
        "!pip install -q condacolab\n",
        "import condacolab\n",
        "condacolab.install()"
      ],
      "metadata": {
        "id": "ggDvnY_yCsYC",
        "outputId": "c3e5f905-c570-4b8a-88e2-b22bbe502323",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚è¨ Downloading https://github.com/conda-forge/miniforge/releases/download/23.1.0-1/Mambaforge-23.1.0-1-Linux-x86_64.sh...\n",
            "üì¶ Installing...\n",
            "üìå Adjusting configuration...\n",
            "ü©π Patching environment...\n",
            "‚è≤ Done in 0:00:17\n",
            "üîÅ Restarting kernel...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a conda environment\n",
        "#!conda env create --name egovision -f aml22-ego/requirements.yaml\n",
        "\n",
        "!mkdir -p /usr/local/envs/egovision\n",
        "!tar xf /content/drive/MyDrive/egovision.tar.gz --directory=/usr/local/envs/egovision"
      ],
      "metadata": {
        "id": "f8_EEKFeCuK9"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###¬†Playground\n"
      ],
      "metadata": {
        "id": "zEVXRviCeEqe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "#VAE EMG train and save\n",
        "\n",
        "cd aml22-ego && git pull origin vae\n",
        "\n",
        "PYTHON_PATH=/usr/local/envs/egovision/bin/python\n",
        "\n",
        "$PYTHON_PATH train_VAE_EMG.py action=\"train_and_save\" \\\n",
        "  name=\"VAE_EMG\" \\\n",
        "  config=configs/VAE_save_feat_EMG.yaml \\\n",
        "  dataset.shift=ActionNet-ActionNet \\\n",
        "  wandb_name='vae' \\\n",
        "  wandb_dir='Experiment_logs'  \\\n",
        "  dataset.RGB.data_path=../ek_data/frames \\\n",
        "  dataset.EMG.features_name='ACTIONNET_EMG/EMG_Normalized_no-clip' \\\n",
        "  models.EMG.model='EMG_VAE' \\\n",
        "  models.EMG.lr=1e-4\n"
      ],
      "metadata": {
        "id": "5b1WDwGBC8R2",
        "outputId": "7e4d51ec-baf4-49d4-ae96-10ea8459f6e4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Updating 09f818b..0d66e8c\n",
            "Fast-forward\n",
            " train_VAE_EMG.py | 2 +-\n",
            " 1 file changed, 1 insertion(+), 1 deletion(-)\n",
            "Clip shape: torch.Size([32, 16, 32, 32])\n",
            "Clip shape: torch.Size([32, 16, 32, 32])\n",
            "Clip shape: torch.Size([32, 16, 32, 32])\n",
            "Clip shape: torch.Size([32, 16, 32, 32])\n",
            "Clip shape: torch.Size([32, 16, 32, 32])\n",
            "Clip shape: torch.Size([32, 16, 32, 32])\n",
            "Clip shape: torch.Size([32, 16, 32, 32])\n",
            "Clip shape: torch.Size([32, 16, 32, 32])\n",
            "Clip shape: torch.Size([32, 16, 32, 32])\n",
            "Clip shape: torch.Size([32, 16, 32, 32])\n",
            "Clip shape: torch.Size([32, 16, 32, 32])\n",
            "Clip shape: torch.Size([32, 16, 32, 32])\n",
            "Clip shape: torch.Size([32, 16, 32, 32])\n",
            "Clip shape: torch.Size([32, 16, 32, 32])\n",
            "Clip shape: torch.Size([32, 16, 32, 32])\n",
            "Clip shape: torch.Size([32, 16, 32, 32])\n",
            "Clip shape: torch.Size([32, 16, 32, 32])\n",
            "Clip shape: torch.Size([32, 16, 32, 32])\n",
            "Clip shape: torch.Size([32, 16, 32, 32])\n",
            "Clip shape: torch.Size([32, 16, 32, 32])\n",
            "Clip shape: torch.Size([32, 16, 32, 32])\n",
            "Clip shape: torch.Size([32, 16, 32, 32])\n",
            "Clip shape: torch.Size([32, 16, 32, 32])\n",
            "Clip shape: torch.Size([32, 16, 32, 32])\n",
            "Clip shape: torch.Size([32, 16, 32, 32])\n",
            "Clip shape: torch.Size([32, 16, 32, 32])\n",
            "Clip shape: torch.Size([32, 16, 32, 32])\n",
            "Clip shape: torch.Size([32, 16, 32, 32])\n",
            "Clip shape: torch.Size([32, 16, 32, 32])\n",
            "Clip shape: torch.Size([32, 16, 32, 32])\n",
            "Clip shape: torch.Size([32, 16, 32, 32])\n",
            "Clip shape: torch.Size([32, 16, 32, 32])\n",
            "Clip shape: torch.Size([32, 16, 32, 32])\n",
            "Clip shape: torch.Size([32, 16, 32, 32])\n",
            "Clip shape: torch.Size([32, 16, 32, 32])\n",
            "Clip shape: torch.Size([32, 16, 32, 32])\n",
            "Clip shape: torch.Size([32, 16, 32, 32])\n",
            "Clip shape: torch.Size([32, 16, 32, 32])\n",
            "Clip shape: torch.Size([32, 16, 32, 32])\n",
            "Clip shape: torch.Size([32, 16, 32, 32])\n",
            "Clip shape: torch.Size([32, 16, 32, 32])\n",
            "Clip shape: torch.Size([32, 16, 32, 32])\n",
            "Clip shape: torch.Size([32, 16, 32, 32])\n",
            "Clip shape: torch.Size([32, 16, 32, 32])\n",
            "Clip shape: torch.Size([32, 16, 32, 32])\n",
            "Clip shape: torch.Size([32, 16, 32, 32])\n",
            "Clip shape: torch.Size([32, 16, 32, 32])\n",
            "Clip shape: torch.Size([32, 16, 32, 32])\n",
            "Clip shape: torch.Size([32, 16, 32, 32])\n",
            "Clip shape: torch.Size([32, 16, 32, 32])\n",
            "Clip shape: torch.Size([32, 16, 32, 32])\n",
            "Clip shape: torch.Size([32, 16, 32, 32])\n",
            "Clip shape: torch.Size([32, 16, 32, 32])\n",
            "Clip shape: torch.Size([32, 16, 32, 32])\n",
            "Clip shape: torch.Size([32, 16, 32, 32])\n",
            "Clip shape: torch.Size([32, 16, 32, 32])\n",
            "Clip shape: torch.Size([32, 16, 32, 32])\n",
            "Clip shape: torch.Size([32, 16, 32, 32])\n",
            "Clip shape: torch.Size([32, 16, 32, 32])\n",
            "Clip shape: torch.Size([32, 16, 32, 32])\n",
            "Clip shape: torch.Size([32, 16, 32, 32])\n",
            "Clip shape: torch.Size([32, 16, 32, 32])\n",
            "Clip shape: torch.Size([32, 16, 32, 32])\n",
            "Clip shape: torch.Size([32, 16, 32, 32])\n",
            "Clip shape: torch.Size([32, 16, 32, 32])\n",
            "Clip shape: torch.Size([32, 16, 32, 32])\n",
            "Clip shape: torch.Size([32, 16, 32, 32])\n",
            "Clip shape: torch.Size([32, 16, 32, 32])\n",
            "Clip shape: torch.Size([32, 16, 32, 32])\n",
            "Clip shape: torch.Size([32, 16, 32, 32])\n",
            "Clip shape: torch.Size([32, 16, 32, 32])\n",
            "Clip shape: torch.Size([32, 16, 32, 32])\n",
            "Clip shape: torch.Size([32, 16, 32, 32])\n",
            "Clip shape: torch.Size([32, 16, 32, 32])\n",
            "Clip shape: torch.Size([32, 16, 32, 32])\n",
            "Clip shape: torch.Size([32, 16, 32, 32])\n",
            "Clip shape: torch.Size([32, 16, 32, 32])\n",
            "Clip shape: torch.Size([32, 16, 32, 32])\n",
            "Clip shape: torch.Size([32, 16, 32, 32])\n",
            "Clip shape: torch.Size([32, 16, 32, 32])\n",
            "[1/100] - Loss: 366154.4578125\n",
            "Clip shape: torch.Size([32, 16, 32, 32])\n",
            "Clip shape: torch.Size([32, 16, 32, 32])\n",
            "Clip shape: torch.Size([32, 16, 32, 32])\n",
            "Clip shape: torch.Size([32, 16, 32, 32])\n",
            "Clip shape: torch.Size([32, 16, 32, 32])\n",
            "Clip shape: torch.Size([32, 16, 32, 32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "From https://github.com/gabbiurlaro/aml22-ego\n",
            " * branch            vae        -> FETCH_HEAD\n",
            "   09f818b..0d66e8c  vae        -> origin/vae\n",
            "2023-05-26 19:49:00 LOG INFO Running with parameters: \n",
            "  action: train_and_save\n",
            "  name: VAE_EMG\n",
            "  modality: ['EMG']\n",
            "  total_batch: 128\n",
            "  batch_size: 32\n",
            "  gpus: None\n",
            "  wandb_name: vae\n",
            "  resume_from: None\n",
            "  logname: train_and_save_ActionNet-ActionNet.log\n",
            "  models_dir: saved_models/VAE_EMG/May26_19-48-56\n",
            "  train:\n",
            "    num_iter: 2500\n",
            "    lr_steps: 500\n",
            "    eval_freq: 50\n",
            "    num_clips: 1\n",
            "    dense_sampling:\n",
            "      RGB: True\n",
            "      EMG: True\n",
            "    num_frames_per_clip:\n",
            "      RGB: 16\n",
            "      EMG: 32\n",
            "  save:\n",
            "    num_clips: 5\n",
            "    dense_sampling:\n",
            "      RGB: True\n",
            "      EMG: True\n",
            "    num_frames_per_clip:\n",
            "      RGB: 16\n",
            "      EMG: 16\n",
            "  test:\n",
            "    num_clips: 5\n",
            "    dense_sampling:\n",
            "      RGB: True\n",
            "      EMG: True\n",
            "    num_frames_per_clip:\n",
            "      RGB: 16\n",
            "      EMG: 32\n",
            "  dataset:\n",
            "    annotations_path: ../drive/MyDrive/train_val_EMG\n",
            "    shift: ActionNet-ActionNet\n",
            "    workers: 4\n",
            "    stride: 2\n",
            "    resolution: 224\n",
            "    RGB:\n",
            "      data_path: ../ek_data/frames\n",
            "      tmpl: img_{:010d}.jpg\n",
            "      features_name: test_feat_kinetics\n",
            "    Event:\n",
            "      rgb4e: 6\n",
            "    EMG:\n",
            "      features_name: ACTIONNET_EMG/EMG_Normalized_no-clip\n",
            "  split: train\n",
            "  augmentation: True\n",
            "  models:\n",
            "    EMG:\n",
            "      model: EMG_VAE\n",
            "      dropout: 0.2\n",
            "      normalize: True\n",
            "      kwargs:\n",
            "      lr_steps: 30\n",
            "      epochs: 100\n",
            "      lr: 0.0001\n",
            "      lr_gamma: 0.1\n",
            "      sgd_momentum: 0.9\n",
            "      weight_decay: 1e-07\n",
            "  config: configs/VAE_save_feat_EMG.yaml\n",
            "  wandb_dir: Experiment_logs\n",
            "  experiment_dir: VAE_EMG/May26_19-48-56\n",
            "  log_dir: TEST_RESULTS/VAE_EMG\n",
            "  logfile: TEST_RESULTS/VAE_EMG/train_and_save_ActionNet-ActionNet.log\n",
            "wandb: Currently logged in as: salvatoreadalberto-esposito (egovision-aml22). Use `wandb login --relogin` to force relogin\n",
            "wandb: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "wandb: wandb version 0.15.3 is available!  To upgrade, please run:\n",
            "wandb:  $ pip install wandb --upgrade\n",
            "wandb: Tracking run with wandb version 0.13.4\n",
            "wandb: Run data is saved locally in /content/aml22-ego/wandb/run-20230526_194902-3jpdq55l\n",
            "wandb: Run `wandb offline` to turn off syncing.\n",
            "wandb: Syncing run summer-wildflower-218\n",
            "wandb: ‚≠êÔ∏è View project at https://wandb.ai/egovision-aml22/FC-VAE%28EMG%29\n",
            "wandb: üöÄ View run at https://wandb.ai/egovision-aml22/FC-VAE%28EMG%29/runs/3jpdq55l\n",
            "2023-05-26 19:49:05 LOG INFO Instantiating models per modality\n",
            "2023-05-26 19:49:05 LOG INFO EMG_VAE Net\tModality: EMG\n",
            "2023-05-26 19:49:08 LOG INFO Dataloader for ActionNet-train with 526 samples generated\n",
            "/usr/local/envs/egovision/lib/python3.7/site-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "2023-05-26 19:49:10 LOG INFO Dataloader for ActionNet-test with 59 samples generated\n",
            "/usr/local/envs/egovision/lib/python3.7/site-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "2023-05-26 19:49:10 LOG INFO Dataloader for ActionNet-train with 526 samples generated\n",
            "/usr/local/envs/egovision/lib/python3.7/site-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "2023-05-26 19:49:11 LOG INFO Dataloader for ActionNet-test with 59 samples generated\n",
            "/usr/local/envs/egovision/lib/python3.7/site-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "2023-05-26 19:49:12 LOG INFO Dataloader for ActionNet-train with 526 samples generated\n",
            "/usr/local/envs/egovision/lib/python3.7/site-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "2023-05-26 19:49:13 LOG INFO Dataloader for ActionNet-test with 59 samples generated\n",
            "/usr/local/envs/egovision/lib/python3.7/site-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "2023-05-26 19:49:13 LOG INFO Dataloader for ActionNet-train with 526 samples generated\n",
            "/usr/local/envs/egovision/lib/python3.7/site-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "2023-05-26 19:49:14 LOG INFO Dataloader for ActionNet-test with 59 samples generated\n",
            "/usr/local/envs/egovision/lib/python3.7/site-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "2023-05-26 19:49:15 LOG INFO Dataloader for ActionNet-train with 526 samples generated\n",
            "/usr/local/envs/egovision/lib/python3.7/site-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "2023-05-26 19:49:15 LOG INFO Dataloader for ActionNet-test with 59 samples generated\n",
            "/usr/local/envs/egovision/lib/python3.7/site-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "2023-05-26 19:49:15 LOG INFO Dataloader for ActionNet-train with 526 samples generated\n",
            "/usr/local/envs/egovision/lib/python3.7/site-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "2023-05-26 19:49:15 LOG INFO Dataloader for ActionNet-test with 59 samples generated\n",
            "/usr/local/envs/egovision/lib/python3.7/site-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "2023-05-26 19:49:15 LOG INFO Start VAE training.\n",
            "Traceback (most recent call last):\n",
            "  File \"train_VAE_EMG.py\", line 399, in <module>\n",
            "    main()\n",
            "  File \"train_VAE_EMG.py\", line 168, in main\n",
            "    ae = train(models, train_loader, train_loader, val_loader, device, args.models.EMG)\n",
            "  File \"train_VAE_EMG.py\", line 313, in train\n",
            "    raise ValueError(\"Loss is NaN.\")\n",
            "ValueError: Loss is NaN.\n",
            "2023-05-26 19:52:18 LOG ERROR Uncaught exception\n",
            "Traceback (most recent call last):\n",
            "  File \"train_VAE_EMG.py\", line 399, in <module>\n",
            "    main()\n",
            "  File \"train_VAE_EMG.py\", line 168, in main\n",
            "    ae = train(models, train_loader, train_loader, val_loader, device, args.models.EMG)\n",
            "  File \"train_VAE_EMG.py\", line 313, in train\n",
            "    raise ValueError(\"Loss is NaN.\")\n",
            "ValueError: Loss is NaN.\n",
            "wandb: Waiting for W&B process to finish... (failed 1). Press Control-C to abort syncing.\n",
            "wandb: \n",
            "wandb: Run history:\n",
            "wandb:        KLD_loss ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
            "wandb:        MSE LOSS ‚ñÇ‚ñÇ‚ñÇ‚ñÖ‚ñÖ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñà‚ñà‚ñÑ‚ñÑ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñá‚ñá‚ñá‚ñÑ‚ñÑ\n",
            "wandb:            loss ‚ñÇ‚ñÇ‚ñÇ‚ñÖ‚ñÖ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñà‚ñà‚ñÑ‚ñÑ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñá‚ñá‚ñá‚ñÑ‚ñÑ\n",
            "wandb:              lr ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
            "wandb: validation_loss ‚ñÅ\n",
            "wandb: \n",
            "wandb: Run summary:\n",
            "wandb:        KLD_loss 14544.07227\n",
            "wandb:        MSE LOSS 1803832.125\n",
            "wandb:            loss 1803832.25\n",
            "wandb:              lr 0.0001\n",
            "wandb: validation_loss 8428291.0\n",
            "wandb: \n",
            "wandb: Synced summer-wildflower-218: https://wandb.ai/egovision-aml22/FC-VAE%28EMG%29/runs/3jpdq55l\n",
            "wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
            "wandb: Find logs at: ./wandb/run-20230526_194902-3jpdq55l/logs\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "CalledProcessError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-176cd6b34fad>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'bash'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'#VAE EMG train and save\\n\\ncd aml22-ego && git pull origin vae\\n\\nPYTHON_PATH=/usr/local/envs/egovision/bin/python\\n\\n$PYTHON_PATH train_VAE_EMG.py action=\"train_and_save\" \\\\\\n  name=\"VAE_EMG\" \\\\\\n  config=configs/VAE_save_feat_EMG.yaml \\\\\\n  dataset.shift=ActionNet-ActionNet \\\\\\n  wandb_name=\\'vae\\' \\\\\\n  wandb_dir=\\'Experiment_logs\\'  \\\\\\n  dataset.RGB.data_path=../ek_data/frames \\\\\\n  dataset.EMG.features_name=\\'ACTIONNET_EMG/EMG_Normalized_no-clip\\' \\\\\\n  models.EMG.model=\\'EMG_VAE\\' \\\\\\n  models.EMG.lr=1e-4\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_shell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m    332\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m       \u001b[0mcell\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 334\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2471\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2472\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2473\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2474\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2475\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/magics/script.py\u001b[0m in \u001b[0;36mnamed_script_magic\u001b[0;34m(line, cell)\u001b[0m\n\u001b[1;32m    140\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m                 \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscript\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshebang\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0;31m# write a basic docstring:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<decorator-gen-103>\u001b[0m in \u001b[0;36mshebang\u001b[0;34m(self, line, cell)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/magics/script.py\u001b[0m in \u001b[0;36mshebang\u001b[0;34m(self, line, cell)\u001b[0m\n\u001b[1;32m    243\u001b[0m             \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_error\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mCalledProcessError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_script\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_close\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mCalledProcessError\u001b[0m: Command 'b'#VAE EMG train and save\\n\\ncd aml22-ego && git pull origin vae\\n\\nPYTHON_PATH=/usr/local/envs/egovision/bin/python\\n\\n$PYTHON_PATH train_VAE_EMG.py action=\"train_and_save\" \\\\\\n  name=\"VAE_EMG\" \\\\\\n  config=configs/VAE_save_feat_EMG.yaml \\\\\\n  dataset.shift=ActionNet-ActionNet \\\\\\n  wandb_name=\\'vae\\' \\\\\\n  wandb_dir=\\'Experiment_logs\\'  \\\\\\n  dataset.RGB.data_path=../ek_data/frames \\\\\\n  dataset.EMG.features_name=\\'ACTIONNET_EMG/EMG_Normalized_no-clip\\' \\\\\\n  models.EMG.model=\\'EMG_VAE\\' \\\\\\n  models.EMG.lr=1e-4\\n'' returned non-zero exit status 1."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "!zip -r /content/feats_augs_2050.zip /content/drive/MyDrive/EXTRACTED_FEATURES_AUG_1\n",
        "files.download('/content/feats_augs_2050.zip')"
      ],
      "metadata": {
        "id": "VldLhOA_iTj3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}